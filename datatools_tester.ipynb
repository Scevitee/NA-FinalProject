{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This only exists for testing new data functions I may add, please make sure you are importing `datatools.jl` when working on the assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/justin/Documents/Spring2024/NumericalAnalysis/NA-FinalProject/data\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const ROOT_PATH = @__DIR__\n",
    "const DATA_PATH = \"$ROOT_PATH/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_datafiles"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "get_datafiles(foldername::String)\n",
    "\n",
    "takes in the name of a folder or path to subfolder in /data/\n",
    "and returns an array of the paths to the different file names \n",
    "\n",
    "\n",
    "data_left_sideOf_center_dr = get_datafiles(\"Center/Left\")\n",
    "\n",
    "--> [\"NA-FinalProject/data/Center/Left/Location-Justin-04-04\", etc]\n",
    "\"\"\"\n",
    "function get_datafiles(foldername::String)\n",
    "     filelist = readdir(\"$DATA_PATH/$foldername\", join=true)\n",
    "     return filelist\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_folder_dataframes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "get_folder_dataframes(foldername::String)\n",
    "\n",
    "takes in the name of a folder or the path to a subfolder in /data/\n",
    "returns a vector of all the dataframes in that folder\n",
    "\n",
    "\n",
    "\n",
    "sweetwater_dataframes = get_folder_dataframes(\"Sweetwater\")\n",
    "\n",
    "\"\"\"\n",
    "function get_folder_dataframes(foldername::String)\n",
    "     filelist = get_datafiles(foldername)\n",
    "\n",
    "     dfs = []\n",
    "     for path in filelist\n",
    "          data = CSV.File(open(path)) |> DataFrame \n",
    "          push!(dfs, data)\n",
    "     end\n",
    "     return dfs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filter_matching_rows"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "filter_matching_rows(dfs::Vector{Any}, column_name::String; round_to::Int=6)\n",
    "\n",
    "takes in a vector of dataframes and a column to filter them by. It looks through the dataframes\n",
    "and keeps rows in which the values match. Can specify how close you want values to be by \n",
    "using round_to to adjust the precision. Returns a vector of the resulting dataframes\n",
    "\n",
    "\n",
    "filtered_dfs = (dfs, \"latitude\"; round_to=5)\n",
    "\"\"\"\n",
    "function filter_matching_rows(dfs::Vector{Any}, column_name::String=\"latitude\"; round_to::Int=5)\n",
    "    # Ensure there is at least one data frame\n",
    "    if isempty(dfs)\n",
    "        error(\"The input vector must contain at least one data frame.\")\n",
    "    end\n",
    "    \n",
    "    # Ensure the column exists in all data frames\n",
    "    for df in dfs\n",
    "        if !(column_name in names(df))\n",
    "            error(\"The specified column must exist in all data frames.\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Apply rounding and find the intersection of rounded values across all data frames\n",
    "    rounded_values_sets = [Set(round.(df[!, column_name], digits=round_to)) for df in dfs]\n",
    "    matching_values = reduce(intersect, rounded_values_sets)\n",
    "    \n",
    "    # Filter all data frames to only include rows with values (rounded) in the matching set\n",
    "    filtered_dfs = [\n",
    "        filter(row -> round(row[column_name], digits=round_to) in matching_values, df)\n",
    "        for df in dfs\n",
    "    ]\n",
    "    \n",
    "    return filtered_dfs\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_filtered_points"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "get_filtered_points(dfs::Vector{Any}, column_name::String; round_to::Int=6, only_unique::Bool=true)\n",
    "\n",
    "Takes in vector of dataframes generated by get_folder_dataframes. User specifies a column_name \n",
    "by which to compare the dataframes. Values are rounded 6 by default, but can be changed. \n",
    "The dataframes are trimmed based on these matching rounded values, and only the columns \n",
    "latitude, longitude, and altitude are returned. These are all that are needed for displaying the\n",
    "points \n",
    "\n",
    "\n",
    "filtered_points = get_filtered_points(folder_dataframes, \"latitude\"; round_to=3)\n",
    "\n",
    "\"\"\"\n",
    "function get_filtered_points(dfs::Vector{Any}, column_name::String=\"latitude\"; round_to::Int=5, only_unique::Bool=true)\n",
    "     filtered_dfs = filter_matching_rows(dfs, column_name; round_to=round_to)\n",
    "\n",
    "     filtered_points = []\n",
    "\n",
    "     for df in filtered_dfs\n",
    "          map!(x->round(x, digits=round_to), df[!, column_name], df[!, column_name])\n",
    "          new_df = select(df, [\"latitude\", \"longitude\", \"altitude\"])\n",
    "          if only_unique\n",
    "               unique!(new_df, column_name)\n",
    "          end\n",
    "          sort!(new_df, column_name)\n",
    "          push!(filtered_points, new_df)\n",
    "     end\n",
    "     \n",
    "     return filtered_points\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stack_df_vectors"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "stack_df_vectors(dfs::Vector{Any})\n",
    "\n",
    "Takes in a vector of dataframes and combines them into one dataframe. It adds in a column titled \"sample\" to indicate which\n",
    "data sample a given row comes from. \n",
    "\"\"\"\n",
    "function stack_df_vectors(dfs::Vector{Any})\n",
    "     for i = 1:length(dfs)\n",
    "          df = dfs[i]\n",
    "          df.sample = fill(\"Sample $i\", nrow(df))\n",
    "     end\n",
    "\n",
    "     a = dfs[1]\n",
    "     for i = 2:length(dfs)\n",
    "          append!(a, dfs[i])\n",
    "     end\n",
    "     \n",
    "     return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "combine_df_vectors"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "combine_df_vectors(dfs::Vector{Any})\n",
    "\n",
    "This function takes in a vector of dataframes from the same road (similar samples).\n",
    "It will compare the vectors and average them together. Unique sample latitudes will instead \n",
    "be appended into the new dataframe. The function assumes that you are passing in the returned value of \n",
    "get_filtered_points, but allows for you to set already_filtered=false if the data is unfiltered\n",
    "\"\"\"\n",
    "function combine_df_vectors(dfs::Vector{Any}; already_filtered::Bool=true, round_to::Int=5)\n",
    "\n",
    "     if already_filtered\n",
    "          dfs = dfs\n",
    "     else\n",
    "          dfs = get_filtered_points(dfs; round_to=round_to)\n",
    "     end\n",
    "\n",
    "     points = Dict()\n",
    "\n",
    "     for df in dfs\n",
    "          for i = 1:length(df[!, :1])\n",
    "               if df.latitude[i] in keys(points)\n",
    "                    push!((points[df.latitude[i]]).alt, df.altitude[i])\n",
    "               else\n",
    "                    points[df.latitude[i]] = (alt=[df.altitude[i]], long=df.longitude[i])\n",
    "               end\n",
    "          end\n",
    "     end \n",
    "\n",
    "     lats = [k for k in keys(points)]\n",
    "     longs = [v.long for v in values(points)]\n",
    "     alts = [mean(v.alt) for v in values(points)]\n",
    "\n",
    "     d = DataFrame(latitude=lats, longitude=longs, altitude=alts)\n",
    "\n",
    "     sort!(d, \"latitude\")\n",
    "\n",
    "     return d\n",
    "          \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_spaced_nodes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    get_spaced_nodes(x, y, n=10; rev=true)\n",
    "\n",
    "Takens in x and y values. returns 'n' number of spaced out points from the data.\n",
    "By default this will return evenly spaced points, but setting fluctuation=SOME_INT will \n",
    "cause each index to fluctuate by ± the inputted value\n",
    "\"\"\"\n",
    "function get_spaced_nodes(x, y, n=10; fluctuation::Int=0)\n",
    "     len = length(x)\n",
    "     indices = round.(Int, LinRange(1, len, n))\n",
    "\n",
    "\n",
    "     for i = 2:length(indices)-1\n",
    "        indices[i] += rand((-1 * fluctuation):fluctuation)\n",
    "     end\n",
    "    \n",
    "     @show indices\n",
    "\n",
    "     if !issorted(x)\n",
    "          sort!(x)\n",
    "     end\n",
    "           \n",
    "     xs = x[indices]\n",
    "     ys = y[indices]\n",
    "\n",
    "     return xs, ys\n",
    " end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_all_dataframes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    get_all_dataframes()\n",
    "\n",
    "Gets all the dataframes from the folders and stores them in a dictionary. The keys of the \n",
    "dictionary are the street that the dataframes belong to. The values of the dictionary are\n",
    "vectors of dataframes, with each dataframe representing a sample taken on said street.\n",
    "\"\"\"\n",
    " function get_all_dataframes()\n",
    "     folders = [\"Center/East\", \"Center/West\", \"Gale/East\", \"Gale/West\", \"Museum\", \"Sweetwater\"]\n",
    "\n",
    "     all_dfs = Dict()\n",
    "\n",
    "     for folder in folders\n",
    "          all_dfs[folder] = get_folder_dataframes(folder)\n",
    "     end\n",
    "\n",
    "     return all_dfs\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything below this line is in progress\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stack_all_streets (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function stack_all_streets(dict::Dict{Any, Any})\n",
    "     combined_df = DataFrame()\n",
    " \n",
    "     for (street, dfs) in dict\n",
    "         street_df = stack_df_vectors(dfs)\n",
    "         \n",
    "         street_df.street = fill(street, nrow(street_df))\n",
    "         \n",
    "         if isempty(combined_df)\n",
    "             combined_df = street_df\n",
    "         else\n",
    "             append!(combined_df, street_df)\n",
    "         end\n",
    "     end\n",
    "     \n",
    "     return combined_df\n",
    " end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11055-element Vector{Float64}:\n",
       "  19.45004165537194\n",
       "  19.45004165537194\n",
       "  14.45004165537194\n",
       "  14.45004165537194\n",
       "  14.45004165537194\n",
       "  14.45004165537194\n",
       "  17.10987915229881\n",
       "  17.10987915229881\n",
       "  17.30955540703777\n",
       "  17.30955540703777\n",
       "   ⋮\n",
       " 172.450038794349\n",
       " 172.450038794349\n",
       " 172.450038794349\n",
       " 172.450038794349\n",
       " 172.450038794349\n",
       " 172.450038794349\n",
       " 172.450038794349\n",
       " 172.450038794349\n",
       " 172.450038794349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_dfs = get_all_dataframes()\n",
    "\n",
    "df = stack_all_streets(all_dfs);\n",
    "\n",
    "smallest = df.altitude[argmin(df.altitude)]\n",
    "\n",
    "df.altitude = (df.altitude .- smallest .+ 0.001) .* 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alldata.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CSV.write(\"alldata.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11055-element Vector{Float64}:\n",
       " -3.0999999046325684\n",
       " -3.0999999046325684\n",
       " -3.5999999046325684\n",
       " -3.5999999046325684\n",
       " -3.5999999046325684\n",
       " -3.5999999046325684\n",
       " -3.334016154939882\n",
       " -3.334016154939882\n",
       " -3.314048529465986\n",
       " -3.314048529465986\n",
       "  ⋮\n",
       " 12.199999809265137\n",
       " 12.199999809265137\n",
       " 12.199999809265137\n",
       " 12.199999809265137\n",
       " 12.199999809265137\n",
       " 12.199999809265137\n",
       " 12.199999809265137\n",
       " 12.199999809265137\n",
       " 12.199999809265137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
